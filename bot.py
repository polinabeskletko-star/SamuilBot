import os
import re
import json
import random
import asyncio
import logging
from datetime import datetime, time, date, timedelta
from collections import defaultdict, deque
from typing import Dict, List, Tuple, Optional, Any

import pytz
import httpx
from openai import OpenAI, AsyncOpenAI
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
    JobQueue,
)

# ==== SETTINGS & ENV ====

TOKEN = os.environ.get("BOT_TOKEN")
GROUP_CHAT_ID = os.environ.get("GROUP_CHAT_ID")  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "-1001234567890"
TIMEZONE = os.environ.get("BOT_TZ", "Australia/Brisbane")

# Telegram user IDs
TARGET_USER_ID = int(os.environ.get("TARGET_USER_ID", "0"))   # –ú–∞–∫—Å–∏–º

# Optional: –∫—É–¥–∞ —Å–ª–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ–±–µ –≤ –ª–∏—á–∫—É)
ADMIN_CHAT_ID = os.environ.get("ADMIN_CHAT_ID")

# OpenAI
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_IMAGE_MODEL = os.environ.get("OPENAI_IMAGE_MODEL", "gpt-4o-mini")  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client: Optional[AsyncOpenAI] = None
if OPENAI_API_KEY:
    client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# OpenWeather
OPENWEATHER_API_KEY = os.environ.get("OPENWEATHER_API_KEY")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ---------- GLOBAL STATE ----------

# –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ —Å –°–∞–º—É–∏–ª–æ–º: (chat_id, user_id) -> list[{"role": "...", "content": "..."}]
dialog_history: Dict[Tuple[int, int], List[Dict[str, str]]] = defaultdict(list)

# –õ–æ–≥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –≤–µ—á–µ—Ä–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: date_str -> list[str]
daily_summary_log: Dict[str, List[str]] = defaultdict(list)

# –î–µ–¥—É–ø –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–ª–∞–Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
# job_name -> datetime last_sent_at (tz-aware)
_last_scheduled_sent_at: Dict[str, datetime] = {}
# job_name -> deque –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
_last_scheduled_texts: Dict[str, deque] = defaultdict(lambda: deque(maxlen=5))

# –î–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –ú–∞–∫—Å–∏–º—É: —Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Ç–≤–µ—Ç—ã
_last_maxim_replies: deque = deque(maxlen=8)

# –ö—ç—à –¥–ª—è –ø–æ–≥–æ–¥—ã: city -> (data, timestamp)
_weather_cache: Dict[str, Tuple[Dict[str, Any], datetime]] = {}
WEATHER_CACHE_TTL = 300  # 5 –º–∏–Ω—É—Ç

# –ö—ç—à –¥–ª—è OpenAI –æ—Ç–≤–µ—Ç–æ–≤: hash -> (response, timestamp)
_openai_cache: Dict[str, Tuple[str, datetime]] = {}
OPENAI_CACHE_TTL = 600  # 10 –º–∏–Ω—É—Ç

# –ö—ç—à –¥–ª—è "—Å–æ–±—ã—Ç–∏—è –¥–Ω—è": date_key -> (text, timestamp)
_onthisday_cache: Dict[str, Tuple[str, datetime]] = {}
ONTHISDAY_CACHE_TTL = 6 * 3600  # 6 —á–∞—Å–æ–≤

# ---------- HELPERS ----------

def get_tz() -> pytz.BaseTzInfo:
    return pytz.timezone(TIMEZONE)


def is_night_time(dt: datetime) -> bool:
    """–ù–æ—á—å: —Å 22:00 –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –¥–æ 07:00 (07:00 —É–∂–µ –Ω–µ –Ω–æ—á—å)."""
    hour = dt.hour
    return hour >= 22 or hour < 7


async def log_to_admin(context: ContextTypes.DEFAULT_TYPE, message: str):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∞–¥–º–∏–Ω—Å–∫–∏–π —á–∞—Ç."""
    if ADMIN_CHAT_ID:
        try:
            await context.bot.send_message(chat_id=int(ADMIN_CHAT_ID), text=message)
        except Exception as e:
            logger.error(f"Failed to send admin log: {e}")


def generate_cache_key(messages: List[Dict[str, str]], max_tokens: int, temperature: float) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –¥–ª—è –∫—ç—à–∞ OpenAI –∑–∞–ø—Ä–æ—Å–æ–≤."""
    import hashlib
    key_str = f"{json.dumps(messages, sort_keys=True)}:{max_tokens}:{temperature}"
    return hashlib.md5(key_str.encode()).hexdigest()


async def call_openai_chat(
    messages: List[Dict[str, str]],
    max_tokens: int = 120,
    temperature: float = 0.7,
    use_cache: bool = True,
) -> Tuple[Optional[str], Optional[str]]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ OpenAI chat.completions.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
    """
    if client is None:
        return None, "OpenAI client is not configured (no API key)."

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if use_cache:
        cache_key = generate_cache_key(messages, max_tokens, temperature)
        cached_data = _openai_cache.get(cache_key)
        if cached_data:
            response, timestamp = cached_data
            if (datetime.now() - timestamp).total_seconds() < OPENAI_CACHE_TTL:
                logger.debug(f"Using cached OpenAI response for key: {cache_key[:8]}")
                return response, None

    try:
        resp = await client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
        )
        text = (resp.choices[0].message.content or "").strip()
        if not text:
            return None, "Empty response from OpenAI."

        if use_cache:
            cache_key = generate_cache_key(messages, max_tokens, temperature)
            _openai_cache[cache_key] = (text, datetime.now())

        return text, None
    except Exception as e:
        err = f"Error calling OpenAI: {e}"
        logger.error(err)
        return None, err


async def generate_image_from_prompt(prompt: str) -> Tuple[Optional[str], Optional[str]]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ —á–µ—Ä–µ–∑ OpenAI Images –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (image_url, error_message).
    """
    if client is None:
        return None, "OpenAI client is not configured (no API key)."

    try:
        resp = await client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            n=1,
            size="1024x1024",
            quality="standard",
        )
        image_url = resp.data[0].url
        return image_url, None
    except Exception as e:
        err = f"Error calling OpenAI Images: {e}"
        logger.error(err)
        return None, err


# ---------- WEATHER HELPERS ----------

async def fetch_weather_for_city(city_query: str, use_cache: bool = True) -> Optional[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–æ–≥–æ–¥—É –∏–∑ OpenWeather –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –≥–æ—Ä–æ–¥–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ.
    """
    if not OPENWEATHER_API_KEY:
        logger.warning("No OPENWEATHER_API_KEY configured")
        return None

    if use_cache:
        cached_data = _weather_cache.get(city_query)
        if cached_data:
            data, timestamp = cached_data
            if (datetime.now() - timestamp).total_seconds() < WEATHER_CACHE_TTL:
                logger.debug(f"Using cached weather for: {city_query}")
                return data

    url = "https://api.openweathermap.org/data/2.5/weather"
    params = {
        "q": city_query,
        "appid": OPENWEATHER_API_KEY,
        "units": "metric",
        "lang": "ru",
    }

    try:
        async with httpx.AsyncClient(timeout=10) as http_client:
            resp = await http_client.get(url, params=params)

        if resp.status_code != 200:
            logger.error(f"OpenWeather error for '{city_query}': {resp.status_code} {resp.text}")
            return None

        data = resp.json()
        main = data.get("main", {})
        weather_list = data.get("weather", [])
        weather_desc = weather_list[0]["description"] if weather_list else "–±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"

        result = {
            "city": data.get("name", city_query),
            "country": data.get("sys", {}).get("country", ""),
            "temp": main.get("temp"),
            "feels_like": main.get("feels_like"),
            "humidity": main.get("humidity"),
            "description": weather_desc,
        }

        if use_cache:
            _weather_cache[city_query] = (result, datetime.now())

        return result
    except Exception as e:
        logger.error(f"Error fetching weather: {e}")
        return None


def detect_weather_city_from_text(text: str) -> Optional[str]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å, –¥–ª—è –∫–∞–∫–æ–≥–æ –≥–æ—Ä–æ–¥–∞ –ø—Ä–æ—Å—è—Ç –ø–æ–≥–æ–¥—É.
    """
    t = text.lower()

    city_mapping = {
        "–∫–∞–ª—É–≥–µ": "Kaluga,ru",
        "–∫–∞–ª—É–≥–∞": "Kaluga,ru",
        "kaluga": "Kaluga,ru",
        "–±—Ä–∏—Å–±–µ–Ω–µ": "Brisbane,au",
        "–±—Ä–∏—Å–±–µ–Ω": "Brisbane,au",
        "brisbane": "Brisbane,au",
        "–º–æ—Å–∫–≤–µ": "Moscow,ru",
        "–º–æ—Å–∫–≤–∞": "Moscow,ru",
        "moscow": "Moscow,ru",
        "–ø–∏—Ç–µ—Ä–µ": "Saint Petersburg,ru",
        "–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "Saint Petersburg,ru",
        "—Å–ø–±": "Saint Petersburg,ru",
    }

    for russian, english in city_mapping.items():
        if russian in t:
            return english

    m = re.search(r"\b(?:–≤|–≤ –≥–æ—Ä–æ–¥–µ)\s+([–ê-–Ø–∞-—èA-Za-z\-]+)", t)
    if m:
        city_raw = m.group(1)
        if any(cyr_char in city_raw for cyr_char in "–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è"):
            city_lower = city_raw.lower()
            for russian, english in city_mapping.items():
                if city_lower in russian:
                    return english
        return city_raw

    return None


def format_weather_for_prompt(info: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–≥–æ–¥–µ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞."""
    if not info:
        return ""

    parts = []
    city = info.get("city")
    country = info.get("country")
    temp = info.get("temp")
    feels = info.get("feels_like")
    hum = info.get("humidity")
    desc = info.get("description")

    if city:
        location = f"{city}, {country}" if country else str(city)
        parts.append(f"–ü–æ–≥–æ–¥–∞ –≤ {location}")
    if desc:
        parts.append(f"—Å–µ–π—á–∞—Å {desc}")
    if temp is not None:
        parts.append(f"—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ {round(temp)}¬∞C")
    if feels is not None and temp is not None and abs(feels - temp) > 1:
        parts.append(f"–æ—â—É—â–∞–µ—Ç—Å—è –∫–∞–∫ {round(feels)}¬∞C")
    if hum is not None:
        parts.append(f"–≤–ª–∞–∂–Ω–æ—Å—Ç—å {hum}%")

    return ", ".join(parts)


# ---------- TODAY: HOLIDAYS & EVENTS (Wikipedia On This Day) ----------

async def fetch_onthisday_ru(d: date, use_cache: bool = True) -> Optional[str]:
    """
    –ë–µ—Ä—ë–º –ø—Ä–∞–∑–¥–Ω–∏–∫–∏/—Å–æ–±—ã—Ç–∏—è "–≤ —ç—Ç–æ—Ç –¥–µ–Ω—å" –∏–∑ Wikimedia API (ru).
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É–∂–µ –≥–æ—Ç–æ–≤—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è Telegram.
    """
    key = d.isoformat()
    now = datetime.now()

    if use_cache:
        cached = _onthisday_cache.get(key)
        if cached:
            text, ts = cached
            if (now - ts).total_seconds() < ONTHISDAY_CACHE_TTL:
                return text

    mm = f"{d.month:02d}"
    dd = f"{d.day:02d}"
    url = f"https://api.wikimedia.org/feed/v1/wikipedia/ru/onthisday/all/{mm}/{dd}"

    headers = {
        # –í–µ–∂–ª–∏–≤–æ: –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ CDN/endpoint –ª—é–±—è—Ç User-Agent
        "User-Agent": "SamuilBot/1.0 (telegram-bot; onthisday feature)"
    }

    try:
        async with httpx.AsyncClient(timeout=12) as http_client:
            resp = await http_client.get(url, headers=headers)

        if resp.status_code != 200:
            logger.error(f"OnThisDay API error: {resp.status_code} {resp.text[:200]}")
            return None

        data = resp.json()

        def _pick_items(arr: List[Dict[str, Any]], n: int, require_year: bool = False) -> List[Dict[str, Any]]:
            items = arr or []
            random.shuffle(items)
            picked = []
            for it in items:
                if require_year and "year" not in it:
                    continue
                text = it.get("text") or ""
                if not text:
                    continue
                picked.append(it)
                if len(picked) >= n:
                    break
            return picked

        # Wikimedia "all" –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç: events, births, deaths, holidays (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ)
        holidays = _pick_items(data.get("holidays", []), n=2, require_year=False)
        events = _pick_items(data.get("events", []), n=2, require_year=True)

        lines: List[str] = []
        title = f"üìÖ –°–µ–≥–æ–¥–Ω—è ({dd}.{mm})"

        if holidays:
            lines.append("–ü—Ä–∞–∑–¥–Ω–∏–∫–∏:")
            for h in holidays:
                lines.append(f"‚Ä¢ {h.get('text', '').strip()}")

        if events:
            if holidays:
                lines.append("")  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
            lines.append("–°–æ–±—ã—Ç–∏—è:")
            for e in events:
                y = e.get("year")
                t = (e.get("text") or "").strip()
                if y and t:
                    lines.append(f"‚Ä¢ {y}: {t}")
                elif t:
                    lines.append(f"‚Ä¢ {t}")

        if not holidays and not events:
            lines.append("–°–µ–≥–æ–¥–Ω—è –±–µ–∑ —è—Ä–∫–∏—Ö –ø—É–Ω–∫—Ç–æ–≤ –ø–æ –±–∞–∑–µ. –ó–Ω–∞—á–∏—Ç, –º–æ–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å —Å–≤–æ–π –ø–æ–≤–æ–¥ üôÇ")

        text_out = title + "\n" + "\n".join(lines)

        # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É –ø–æ–¥ Telegram (4096), –æ—Å—Ç–∞–≤–∏–º –∑–∞–ø–∞—Å
        if len(text_out) > 3500:
            text_out = text_out[:3500].rsplit("\n", 1)[0] + "\n‚Ä¶"

        _onthisday_cache[key] = (text_out, now)
        return text_out

    except Exception as e:
        logger.error(f"Error fetching onthisday: {e}")
        return None


async def cmd_today(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /today ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –∏ —Å–æ–±—ã—Ç–∏—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è."""
    tz = get_tz()
    now = datetime.now(tz)
    text = await fetch_onthisday_ru(now.date())
    if not text:
        await update.message.reply_text("–ù–µ —Å–º–æ–≥ –¥–æ—Å—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
        return
    await update.message.reply_text(text)


async def today_events_job(context: ContextTypes.DEFAULT_TYPE):
    """–ï–∂–µ–¥–Ω–µ–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ '—á—Ç–æ —Å–µ–≥–æ–¥–Ω—è –∑–∞ –¥–µ–Ω—å'."""
    if not GROUP_CHAT_ID:
        return

    tz = get_tz()
    now = datetime.now(tz)

    logger.info(f"[Today events job] Called at {now}")

    today_str = now.date().isoformat()
    last_send_key = f"today_events_sent_{today_str}"

    if last_send_key in _last_scheduled_sent_at:
        logger.info(f"[Today events] Already sent today ({today_str}), skipping")
        return

    text = await fetch_onthisday_ru(now.date())
    if not text:
        logger.error("[Today events] Failed to fetch onthisday text")
        return

    # –î–µ–¥—É–ø –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    if _should_dedupe_scheduled_send("today_events_job", now, text):
        logger.info("[Today events] DEDUP: skipping duplicate send")
        return

    try:
        await context.bot.send_message(
            chat_id=int(GROUP_CHAT_ID),
            text=text,
        )
        _record_scheduled_send("today_events_job", now, text)
        _last_scheduled_sent_at[last_send_key] = now
        logger.info(f"[Today events] Sent at {now}")
    except Exception as e:
        logger.error(f"Error sending today events message: {e}")


# ---------- AI MESSAGE GENERATORS ----------

MAX_QA_TOKENS = 160
MAX_MAXIM_REPLY_TOKENS = 70
MAX_SCHEDULED_TOKENS = 90

def get_time_context(hour: int) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤."""
    if hour < 6:
        return "–ù–æ—á—å."
    elif hour < 12:
        return "–£—Ç—Ä–æ."
    elif hour < 17:
        return "–î–µ–Ω—å."
    elif hour < 22:
        return "–í–µ—á–µ—Ä."
    else:
        return "–ü–æ–∑–¥–Ω–∏–π –≤–µ—á–µ—Ä."


def build_samuil_system_prompt(include_maxim_context: bool = False) -> str:
    """–°–æ–∑–¥–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –°–∞–º—É–∏–ª–∞."""
    base = (
        "–¢—ã ‚Äî –°–∞–º—É–∏–ª, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π, –Ω–æ –≤ —Ü–µ–ª–æ–º –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç.\n"
        "–ì–æ–≤–æ—Ä–∏—à—å –ø–æ-—Ä—É—Å—Å–∫–∏, –Ω–∞ '—Ç—ã'.\n"
        "–ò—Ä–æ–Ω–∏—á–Ω—ã–π, –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, –∏–Ω–æ–≥–¥–∞ —Å–ª–µ–≥–∫–∞ –∫–æ–ª–∫–∏–π, –Ω–æ –ù–ï –≥—Ä—É–±—ã–π –∏ –ù–ï —Ç–æ–∫—Å–∏—á–Ω—ã–π.\n"
        "–ü–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –≤ —á–∞—Ç–µ.\n"
        "–≠–º–æ–¥–∑–∏: —Ä–µ–¥–∫–æ, –º–∞–∫—Å–∏–º—É–º 0‚Äì1.\n"
        "–ò–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–æ–≤ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫.\n"
    )

    if not include_maxim_context:
        return base

    maxim_ctx = (
        "\n=== –ö–û–ù–¢–ï–ö–°–¢ –ü–†–û –ú–ê–ö–°–ò–ú–ê ===\n"
        "–§–∞–∫—Ç—ã (–∏—Å–ø–æ–ª—å–∑—É–π 1‚Äì2 –∑–∞ —Ä–∞–∑, –ù–ï —Å–ø–∏—Å–∫–æ–º):\n"
        "- –ø–æ—á—Ç–∏ 40, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—ã–ª –∂–µ–Ω–∞—Ç\n"
        "- –º–∞–º–∞ –∂–¥—ë—Ç –≤–Ω—É–∫–æ–≤, –æ–Ω –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π\n"
        "- –ñ–µ–ª–Ω–∏–Ω —É–µ—Ö–∞–ª, –∫–æ–º–ø–∞–Ω–∏–∏ –º–µ–Ω—å—à–µ\n"
        "- —Å—á–∏—Ç–∞–µ—Ç —Å–µ–±—è –≥–µ–Ω–∏–∞–ª—å–Ω—ã–º –∏ –∏–¥–µ–∞–ª—å–Ω—ã–º, –Ω–æ –æ–¥–∏–Ω–æ–∫\n"
        "- —Ö–æ—á–µ—Ç –¥–µ–≤—É—à–∫—É –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–æ–ª–æ–∂–µ\n"
        "–ò—Ä–æ–Ω–∏—è –ª—ë–≥–∫–∞—è, –∏–Ω—Ç–µ–ª–ª–∏–≥–µ–Ω—Ç–Ω–∞—è.\n"
    )
    return base + maxim_ctx


def _normalize_text_for_dedupe(s: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏."""
    return re.sub(r"\s+", " ", (s or "").strip().lower())


def _should_dedupe_scheduled_send(job_name: str, now: datetime, text: str) -> bool:
    """
    –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–µ–π –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞.
    """
    norm = _normalize_text_for_dedupe(text)
    if not norm:
        return False

    last_at = _last_scheduled_sent_at.get(job_name)
    if last_at is not None:
        time_diff = abs((now - last_at).total_seconds())
        if time_diff < 600:  # 10 –º–∏–Ω—É—Ç
            logger.info(f"Dedupe: too soon since last send ({time_diff:.0f}s)")
            return True

    for prev in _last_scheduled_texts[job_name]:
        prev_norm = _normalize_text_for_dedupe(prev)
        if norm == prev_norm:
            logger.info(f"Dedupe: duplicate text detected for {job_name}")
            return True

        if len(norm) > 20 and len(prev_norm) > 20:
            words_current = set(norm.split())
            words_prev = set(prev_norm.split())
            common_words = words_current.intersection(words_prev)
            similarity = len(common_words) / max(len(words_current), len(words_prev))

            if similarity > 0.8:
                logger.info(f"Dedupe: high similarity ({similarity:.0%}) for {job_name}")
                return True

    return False


def _record_scheduled_send(job_name: str, now: datetime, text: str) -> None:
    """–ó–∞–ø–∏—Å—å —Ñ–∞–∫—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è."""
    _last_scheduled_sent_at[job_name] = now
    _last_scheduled_texts[job_name].append(text)
    logger.info(f"Recorded send for {job_name} at {now}")


async def generate_sarcastic_reply_for_maxim(now: datetime, user_text: str) -> Tuple[Optional[str], Optional[str]]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ú–∞–∫—Å–∏–º–∞."""
    weekday_names = [
        "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–≤—Ç–æ—Ä–Ω–∏–∫", "—Å—Ä–µ–¥–∞",
        "—á–µ—Ç–≤–µ—Ä–≥", "–ø—è—Ç–Ω–∏—Ü–∞", "—Å—É–±–±–æ—Ç–∞", "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ",
    ]
    weekday_name = weekday_names[now.weekday()]
    time_str = now.strftime("%H:%M")
    time_context = get_time_context(now.hour)

    system_prompt = build_samuil_system_prompt(include_maxim_context=True)

    last_replies = "\n".join(f"- {x}" for x in list(_last_maxim_replies)[-6:]) or "- (–Ω–µ—Ç)"
    user_prompt = (
        f"–î–µ–Ω—å: {weekday_name}, –≤—Ä–µ–º—è: {time_str}. {time_context}\n"
        f"–°–æ–æ–±—â–µ–Ω–∏–µ –ú–∞–∫—Å–∏–º–∞: ¬´{user_text}¬ª\n\n"
        f"–ù–ï –ø–æ–≤—Ç–æ—Ä—è–π –¥–æ—Å–ª–æ–≤–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Ç–≤–µ—Ç—ã –°–∞–º—É–∏–ª–∞:\n{last_replies}\n\n"
        "–ó–∞–¥–∞–Ω–∏–µ: –ø—Ä–∏–¥—É–º–∞–π –û–ß–ï–ù–¨ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (–æ–¥–Ω–∞ —Ñ—Ä–∞–∑–∞ –∏–ª–∏ 1‚Äì2 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).\n"
        "–ë–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π. –ü–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –Ω–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞.\n"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    text, err = await call_openai_chat(
        messages,
        max_tokens=MAX_MAXIM_REPLY_TOKENS,
        temperature=0.95,
        use_cache=False
    )

    if text:
        _last_maxim_replies.append(text)
    return text, err


async def generate_samuil_answer(
    now: datetime,
    chat_id: int,
    user_id: int,
    user_text: str,
    weather_info: Optional[Dict[str, Any]] = None,
) -> Tuple[Optional[str], Optional[str]]:
    """–û—Ç–≤–µ—Ç –°–∞–º—É–∏–ª–∞ –Ω–∞ –ø—Ä—è–º–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ."""
    weekday_names = [
        "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–≤—Ç–æ—Ä–Ω–∏–∫", "—Å—Ä–µ–¥–∞",
        "—á–µ—Ç–≤–µ—Ä–≥", "–ø—è—Ç–Ω–∏—Ü–∞", "—Å—É–±–±–æ—Ç–∞", "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ",
    ]
    weekday_name = weekday_names[now.weekday()]
    time_str = now.strftime("%H:%M")

    text_lower = user_text.lower()
    include_maxim_context = (user_id == TARGET_USER_ID) or ("–º–∞–∫—Å–∏–º" in text_lower)

    system_prompt = build_samuil_system_prompt(include_maxim_context=include_maxim_context)
    time_context = get_time_context(now.hour)

    extra_context_parts = [
        f"–°–µ–≥–æ–¥–Ω—è {weekday_name}. {time_context} –°–µ–π—á–∞—Å {time_str}.",
        "–¢—ã –≤ –≥—Ä—É–ø–ø–æ–≤–æ–º —á–∞—Ç–µ. –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.",
    ]

    if weather_info is not None:
        weather_str = format_weather_for_prompt(weather_info)
        extra_context_parts.append(f"–¢–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≥–æ–¥–µ (–∫–∞–∫ —Ñ–∞–∫—Ç): {weather_str}")

    extra_context = " ".join(extra_context_parts)

    key = (chat_id, user_id)
    history = dialog_history[key]

    messages: List[Dict[str, str]] = [{"role": "system", "content": system_prompt}]
    messages.append({"role": "user", "content": extra_context})

    if history:
        trimmed = history[-4:]
        messages.extend(trimmed)

    messages.append({"role": "user", "content": user_text})

    if "?" in user_text:
        messages.append({
            "role": "system",
            "content": "–ï—Å–ª–∏ —ç—Ç–æ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ, –Ω–æ –∫—Ä–∞—Ç–∫–æ (2‚Äì4 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."
        })
    else:
        messages.append({
            "role": "system",
            "content": "–ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–π —Ä–µ–ø–ª–∏–∫–æ–π (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."
        })

    text, err = await call_openai_chat(
        messages,
        max_tokens=MAX_QA_TOKENS,
        temperature=0.85,
        use_cache=False
    )

    if text is not None:
        history.append({"role": "user", "content": user_text})
        history.append({"role": "assistant", "content": text})
        if len(history) > 20:
            dialog_history[key] = history[-20:]
        else:
            dialog_history[key] = history

    return text, err


# ---------- COMMAND HANDLERS ----------

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start."""
    chat_type = update.effective_chat.type
    if chat_type == "private":
        await update.message.reply_text(
            "–ü—Ä–∏–≤–µ—Ç! –Ø –°–∞–º—É–∏–ª ü§ñ\n"
            "–í –≥—Ä—É–ø–ø–µ –∏–Ω–æ–≥–¥–∞ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é –ú–∞–∫—Å–∏–º–∞, "
            "–∞ –µ—Å–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å '–°–∞–º—É–∏–ª' –∏–ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å —Ä–µ–ø–ª–∞–µ–º –Ω–∞ –º–æ—ë —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –æ—Ç–≤–µ—á—É.\n"
            "–ü–æ–≥–æ–¥—É —Ç–æ–∂–µ –º–æ–≥—É –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å. –ö–∞—Ä—Ç–∏–Ω–∫–∏: /img <–∑–∞–ø—Ä–æ—Å>.\n"
            "–°–æ–±—ã—Ç–∏—è –¥–Ω—è: /today."
        )
    else:
        await update.message.reply_text(
            "–Ø –°–∞–º—É–∏–ª. –ó–æ–≤–∏ –ø–æ –∏–º–µ–Ω–∏ (–∏–ª–∏ —Ä–µ–ø–ª–∞–µ–º) ‚Äî –æ—Ç–≤–µ—á—É. "
            "–ò–Ω–æ–≥–¥–∞ –ø–æ–¥–∫–æ–ª—é –ú–∞–∫—Å–∏–º–∞. /img —Ç–æ–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç. /today ‚Äî —á—Ç–æ —Å–µ–≥–æ–¥–Ω—è –∑–∞ –¥–µ–Ω—å."
        )


async def chat_id(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç ID —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞."""
    cid = update.effective_chat.id
    await update.message.reply_text(
        f"Chat ID for this chat: `{cid}`",
        parse_mode="Markdown",
    )


async def whoami(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ."""
    user = update.effective_user
    await update.message.reply_text(
        f"Your user ID: `{user.id}`\nUsername: @{user.username}",
        parse_mode="Markdown",
    )


async def echo_private(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Echo —Ç–æ–ª—å–∫–æ –≤ –ª–∏—á–∫–µ."""
    if update.effective_chat.type != "private":
        return
    text = update.message.text or ""
    await update.message.reply_text(f"–¢—ã –Ω–∞–ø–∏—Å–∞–ª: {text}")


async def cmd_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ö–æ–º–∞–Ω–¥–∞ /img <–æ–ø–∏—Å–∞–Ω–∏–µ> ‚Äì –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É.
    """
    if client is None:
        await update.message.reply_text("–£ –º–µ–Ω—è –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω OpenAI API, –∫–∞—Ä—Ç–∏–Ω–∫—É —Å–¥–µ–ª–∞—Ç—å –Ω–µ –º–æ–≥—É.")
        return

    args = context.args
    if not args:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä: /img –∫–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ")
        return

    prompt = " ".join(args).strip()
    if len(prompt) > 1000:
        await update.message.reply_text("–ó–∞–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –£–∫–æ—Ä–æ—Ç–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")
        return

    status_msg = await update.message.reply_text("üé® –°–æ–∑–¥–∞—é –∫–∞—Ä—Ç–∏–Ω–∫—É...")

    img_url, err = await generate_image_from_prompt(prompt)
    if img_url is None:
        logger.error(f"Image generation error: {err}")
        await status_msg.edit_text("–ù–µ –≤—ã—à–ª–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É. –ü–æ–ø—Ä–æ–±—É–π –ø—Ä–æ—â–µ –∑–∞–ø—Ä–æ—Å.")
        return

    try:
        await status_msg.delete()
        await update.message.chat.send_photo(
            photo=img_url,
            caption=f"üé® {prompt[:100]}{'...' if len(prompt) > 100 else ''}",
        )
    except Exception as e:
        logger.error(f"Error sending image: {e}")
        await update.message.reply_text("–ö–∞—Ä—Ç–∏–Ω–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞—Å—å, –Ω–æ —è –Ω–µ —Å–º–æ–≥ –µ—ë –æ—Ç–ø—Ä–∞–≤–∏—Ç—å.")


async def cmd_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    key = (update.effective_chat.id, update.effective_user.id)
    if key in dialog_history:
        dialog_history[key] = []
        await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")
    else:
        await update.message.reply_text("–£ —Ç–µ–±—è –µ—â—ë –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞.")


async def cmd_stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–æ—Ç–∞."""
    total_dialogs = len(dialog_history)
    total_messages = sum(len(history) for history in dialog_history.values())
    weather_cache_size = len(_weather_cache)
    openai_cache_size = len(_openai_cache)
    onthisday_cache_size = len(_onthisday_cache)

    stats_text = (
        f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –°–∞–º—É–∏–ª–∞:\n"
        f"‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {total_dialogs}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {total_messages}\n"
        f"‚Ä¢ –ì–æ—Ä–æ–¥–æ–≤ –≤ –∫—ç—à–µ –ø–æ–≥–æ–¥—ã: {weather_cache_size}\n"
        f"‚Ä¢ –û—Ç–≤–µ—Ç–æ–≤ –≤ –∫—ç—à–µ OpenAI: {openai_cache_size}\n"
        f"‚Ä¢ –ö—ç—à '—Å–æ–±—ã—Ç–∏—è –¥–Ω—è': {onthisday_cache_size}\n"
        f"‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ú–∞–∫—Å–∏–º—É: {len(_last_maxim_replies)}"
    )

    await update.message.reply_text(stats_text)


# ---------- GROUP MESSAGE HANDLER ----------

def _looks_like_image_request(text_lower: str) -> bool:
    """–≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ –°–∞–º—É–∏–ª—É —Å –ø—Ä–æ—Å—å–±–æ–π –ø—Ä–æ –∫–∞—Ä—Ç–∏–Ω–∫—É."""
    keywords = ["–∫–∞—Ä—Ç–∏–Ω–∫", "—Ñ–æ—Ç–æ", "—Ñ–æ—Ç–∫—É", "–≥–∏—Ñ", "gif", "–º–µ–º", "picture", "image"]
    verbs = ["—Å–¥–µ–ª–∞–π", "–Ω–∞—Ä–∏—Å—É–π", "–Ω–∞–π–¥–∏", "–ø–æ–∫–∞–∂–∏", "–ø—Ä–∏–¥—É–º–∞–π"]
    return any(k in text_lower for k in keywords) and any(v in text_lower for v in verbs)


def _clean_prompt_for_image(text: str) -> str:
    """–£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ."""
    patterns = [
        (r"\b—Å–∞–º—É–∏–ª\b", ""),
        (r"(—Å–¥–µ–ª–∞–π|–Ω–∞—Ä–∏—Å—É–π|–Ω–∞–π–¥–∏|–ø–æ–∫–∞–∂–∏|–ø—Ä–∏–¥—É–º–∞–π)( –º–Ω–µ)?\s+(–∫–∞—Ä—Ç–∏–Ω–∫—É|–º–µ–º|–≥–∏—Ñ–∫—É|—Ñ–æ—Ç–æ)", ""),
        (r"–ø–æ–∂–∞–ª—É–π—Å—Ç–∞\b", ""),
        (r"\s+", " "),
    ]

    result = text.strip()
    for pattern, replacement in patterns:
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)

    return result.strip() or "—Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π –º–µ–º –ø—Ä–æ –æ–¥–∏–Ω–æ–∫–æ–≥–æ –≤–∑—Ä–æ—Å–ª–æ–≥–æ –º—É–∂—á–∏–Ω—É –ø–æ –∏–º–µ–Ω–∏ –ú–∞–∫—Å–∏–º"


async def handle_group_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –≥—Ä—É–ø–ø–µ."""
    message = update.message
    if message is None or message.text is None:
        return

    chat = message.chat
    user = message.from_user
    text = message.text.strip()

    chat_id_val = chat.id
    user_id = user.id

    logger.info(f"Group message: chat={chat_id_val} user={user_id} ({user.username}) text='{text[:50]}...'")

    if GROUP_CHAT_ID:
        try:
            target_chat_id = int(GROUP_CHAT_ID)
            if chat_id_val != target_chat_id:
                return
        except ValueError:
            pass

    tz = get_tz()
    now = datetime.now(tz)
    today_str = now.date().isoformat()

    author_name = user.username or user.full_name or str(user_id)
    daily_summary_log[today_str].append(f"{author_name}: {text}")

    text_lower = text.lower()

    is_reply_to_bot = (
        message.reply_to_message is not None
        and message.reply_to_message.from_user is not None
        and message.reply_to_message.from_user.id == context.bot.id
    )

    # 1) –ü—Ä—è–º–æ–µ –æ–±—â–µ–Ω–∏–µ —Å –°–∞–º—É–∏–ª–æ–º
    if is_reply_to_bot or ("—Å–∞–º—É–∏–ª" in text_lower):
        if _looks_like_image_request(text_lower) and client is not None:
            prompt = _clean_prompt_for_image(text)

            status_msg = await message.chat.send_message("üé® –°–æ–∑–¥–∞—é –∫–∞—Ä—Ç–∏–Ω–∫—É...")

            img_url, err = await generate_image_from_prompt(prompt)
            if img_url is None:
                logger.error(f"Image generation error (dialog): {err}")
                await status_msg.edit_text("–ù–µ –≤—ã—à–ª–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑, –Ω–æ –ø–æ–ø—Ä–æ—â–µ.")
                return

            try:
                await status_msg.delete()
                await message.chat.send_photo(
                    photo=img_url,
                    caption=f"üé® {prompt[:100]}{'...' if len(prompt) > 100 else ''}",
                )
            except Exception as e:
                logger.error(f"Error sending image (dialog): {e}")
                await message.chat.send_message("–ö–∞—Ä—Ç–∏–Ω–∫–∞ –µ—Å—Ç—å, –∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–µ —Å–º–æ–≥.")
            return

        weather_info = None
        if any(keyword in text_lower for keyword in ["–ø–æ–≥–æ–¥", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä", "–∂–∞—Ä–∞", "—Ö–æ–ª–æ–¥", "–¥–æ–∂–¥—å"]):
            city_query = detect_weather_city_from_text(text)
            if city_query:
                weather_info = await fetch_weather_for_city(city_query)

        ai_text, err = await generate_samuil_answer(
            now=now,
            chat_id=chat_id_val,
            user_id=user_id,
            user_text=text,
            weather_info=weather_info,
        )

        if ai_text is None:
            fallbacks = [
                "–Ø –∑–∞–≤–∏—Å. –°–ø—Ä–æ—Å–∏ –µ—â—ë —Ä–∞–∑ –ø–æ–ø—Ä–æ—â–µ.",
                "–°–µ–≥–æ–¥–Ω—è —è –≤ —ç–∫–æ–Ω–æ–º-—Ä–µ–∂–∏–º–µ. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.",
                "–ú–æ–π —Å–∞—Ä–∫–∞–∑–º —É—à—ë–ª –ø–∏—Ç—å —á–∞–π. –í–µ—Ä–Ω—É—Å—å.",
                "–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π ‚Äî —è –Ω–µ —Ç–µ–ª–µ–ø–∞—Ç.",
            ]
            logger.error(f"OpenAI error for Samuil Q&A: {err}")
            await message.chat.send_message(random.choice(fallbacks))
            return

        await message.chat.send_message(ai_text)
        return

    # 2) –°–∞—Ä–∫–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ú–∞–∫—Å–∏–º–∞
    if TARGET_USER_ID and user_id == TARGET_USER_ID:
        if random.random() < 0.40:
            logger.debug("Skipping Maxim's message for variety")
            return

        if len(text) < 3:
            return

        ai_text, err = await generate_sarcastic_reply_for_maxim(now=now, user_text=text)

        if ai_text is None:
            fallbacks = [
                "–ú–∞–∫—Å–∏–º, —ç—Ç–æ –±—ã–ª–æ —Å–º–µ–ª–æ. –ò —Å—Ç—Ä–∞–Ω–Ω–æ.",
                "–ü–æ–Ω—è–ª. –ó–∞–ø–∏—Å–∞–ª. –û—Å—É–¥–∏–ª.",
                "–°–∏–ª—å–Ω–∞—è –º—ã—Å–ª—å. –ü–æ—á—Ç–∏.",
                "–Ø –±—ã –æ—Ç–≤–µ—Ç–∏–ª‚Ä¶ –Ω–æ —Ç—ã —Å–ø—Ä–∞–≤–∏—à—å—Å—è —Å–∞–º.",
            ]
            logger.error(f"OpenAI error for sarcastic_reply: {err}")
            await message.chat.send_message(random.choice(fallbacks))
            return

        await message.chat.send_message(ai_text)
        return


# ---------- SCHEDULED JOBS ----------

async def good_morning_job(context: ContextTypes.DEFAULT_TYPE):
    """–£—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ 07:30."""
    if not GROUP_CHAT_ID:
        return

    tz = get_tz()
    now = datetime.now(tz)

    logger.info(f"[Good morning job] Called at {now}")

    today_str = now.date().isoformat()
    last_send_key = f"good_morning_sent_{today_str}"

    if last_send_key in _last_scheduled_sent_at:
        logger.info(f"[Good morning] Already sent today ({today_str}), skipping")
        return

    weekday_names = [
        "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–≤—Ç–æ—Ä–Ω–∏–∫", "—Å—Ä–µ–¥–∞",
        "—á–µ—Ç–≤–µ—Ä–≥", "–ø—è—Ç–Ω–∏—Ü–∞", "—Å—É–±–±–æ—Ç–∞", "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ",
    ]
    weekday_name = weekday_names[now.weekday()]

    system_prompt = build_samuil_system_prompt(include_maxim_context=True)

    recent = "\n".join(f"- {x}" for x in list(_last_scheduled_texts["good_morning_job"])) or "- (–Ω–µ—Ç)"
    user_prompt = (
        f"–°–µ–≥–æ–¥–Ω—è {weekday_name}. –£—Ç—Ä–æ, 07:30.\n"
        "–°–¥–µ–ª–∞–π –û–ß–ï–ù–¨ –∫–æ—Ä–æ—Ç–∫–æ–µ —É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ú–∞–∫—Å–∏–º—É: 1 —Ñ—Ä–∞–∑–∞ –∏–ª–∏ 1 –∫–æ—Ä–æ—Ç–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.\n"
        "–ë–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π.\n"
        f"–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\n{recent}\n"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    text, err = await call_openai_chat(
        messages,
        max_tokens=MAX_SCHEDULED_TOKENS,
        temperature=0.95,
        use_cache=False
    )

    if text is None:
        logger.error(f"OpenAI error for good morning: {err}")
        return

    if _should_dedupe_scheduled_send("good_morning_job", now, text):
        logger.info("[Good morning] DEDUP: skipping duplicate send")
        return

    try:
        await context.bot.send_message(
            chat_id=int(GROUP_CHAT_ID),
            text=text,
        )
        _record_scheduled_send("good_morning_job", now, text)
        _last_scheduled_sent_at[last_send_key] = now
        logger.info(f"[Good morning] Sent at {now}")
    except Exception as e:
        logger.error(f"Error sending good morning message: {e}")


async def evening_summary_job(context: ContextTypes.DEFAULT_TYPE):
    """–í–µ—á–µ—Ä–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ 21:00."""
    if not GROUP_CHAT_ID:
        return

    tz = get_tz()
    now = datetime.now(tz)

    logger.info(f"[Evening summary job] Called at {now}")

    today_str = now.date().isoformat()
    last_send_key = f"evening_summary_sent_{today_str}"

    if last_send_key in _last_scheduled_sent_at:
        logger.info(f"[Evening summary] Already sent today ({today_str}), skipping")
        return

    messages_today = daily_summary_log.get(today_str, [])

    weekday_names = [
        "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–≤—Ç–æ—Ä–Ω–∏–∫", "—Å—Ä–µ–¥–∞",
        "—á–µ—Ç–≤–µ—Ä–≥", "–ø—è—Ç–Ω–∏—Ü–∞", "—Å—É–±–±–æ—Ç–∞", "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ",
    ]
    weekday_name = weekday_names[now.weekday()]

    unique_messages = []
    seen_authors = set()
    for msg in reversed(messages_today[-12:]):
        author = msg.split(":", 1)[0] if ":" in msg else "unknown"
        if author not in seen_authors:
            unique_messages.append(msg)
            seen_authors.add(author)

    if unique_messages:
        joined = "\n".join(unique_messages[-6:])
        context_msg = f"–ò–∑ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n{joined}\n"
    else:
        context_msg = "–°–µ–≥–æ–¥–Ω—è –≤ —á–∞—Ç–µ —Ç–∏—Ö–æ.\n"

    system_prompt = build_samuil_system_prompt(include_maxim_context=True)

    recent = "\n".join(f"- {x}" for x in list(_last_scheduled_texts["evening_summary_job"])) or "- (–Ω–µ—Ç)"
    user_prompt = (
        f"–°–µ–≥–æ–¥–Ω—è {weekday_name}, 21:00.\n"
        f"{context_msg}\n"
        "–°–¥–µ–ª–∞–π –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: 1‚Äì2 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –º–∏–Ω–∏-–∏—Ç–æ–≥ + —Å–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏ –ú–∞–∫—Å–∏–º—É.\n"
        f"–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\n{recent}\n"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    text, err = await call_openai_chat(
        messages,
        max_tokens=MAX_SCHEDULED_TOKENS,
        temperature=0.95,
        use_cache=False
    )

    if text is None:
        logger.error(f"OpenAI error for evening summary: {err}")
        return

    if _should_dedupe_scheduled_send("evening_summary_job", now, text):
        logger.info("[Evening summary] DEDUP: skipping duplicate send")
        return

    try:
        await context.bot.send_message(
            chat_id=int(GROUP_CHAT_ID),
            text=text,
        )
        _record_scheduled_send("evening_summary_job", now, text)
        _last_scheduled_sent_at[last_send_key] = now
        logger.info(f"[Evening summary] Sent at {now}")

        if today_str in daily_summary_log:
            del daily_summary_log[today_str]

    except Exception as e:
        logger.error(f"Error sending evening summary message: {e}")


# ---------- JOB SCHEDULING MANAGEMENT ----------

class JobManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏."""

    def __init__(self):
        self.jobs_setup = False
        self.setup_time = None
        self.job_names = set()

    async def setup_jobs(self, application: Application):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–µ–π."""
        if self.jobs_setup:
            logger.info("Jobs already set up, skipping...")
            return

        job_queue = application.job_queue
        if not job_queue:
            logger.error("No job queue available!")
            return

        tz = get_tz()
        now = datetime.now(tz)

        # –û–ß–ï–ù–¨ –í–ê–ñ–ù–û: –æ—á–∏—â–∞–µ–º –í–°–ï —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞—á–∏ –°–∞–º—É–∏–ª–∞
        existing_jobs = list(job_queue.jobs())
        jobs_to_remove = []

        for job in existing_jobs:
            if hasattr(job.callback, '__name__'):
                if job.callback.__name__ in ['good_morning_job', 'evening_summary_job', 'today_events_job']:
                    jobs_to_remove.append(job)

        for job in jobs_to_remove:
            try:
                job.schedule_removal()
                logger.info(f"Removed old job: {job.name}")
            except Exception as e:
                logger.error(f"Error removing job {job.name}: {e}")

        await asyncio.sleep(1)

        morning_job = job_queue.run_daily(
            good_morning_job,
            time=time(7, 30, tzinfo=tz),
            name=f"samuil_good_morning_{int(now.timestamp())}",
        )

        # –ù–æ–≤–æ–µ: —Å–æ–±—ã—Ç–∏—è/–ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è (09:00)
        today_job = job_queue.run_daily(
            today_events_job,
            time=time(15, 5, tzinfo=tz),
            name=f"samuil_today_events_{int(now.timestamp())}",
        )

        evening_job = job_queue.run_daily(
            evening_summary_job,
            time=time(21, 0, tzinfo=tz),
            name=f"samuil_evening_summary_{int(now.timestamp())}",
        )

        if morning_job:
            self.job_names.add(morning_job.name)
        if today_job:
            self.job_names.add(today_job.name)
        if evening_job:
            self.job_names.add(evening_job.name)

        self.jobs_setup = True
        self.setup_time = now

        logger.info(f"Jobs scheduled at {now} [{TIMEZONE}]")
        logger.info(f"Morning job: {morning_job.name if morning_job else 'failed'}")
        logger.info(f"Today events job: {today_job.name if today_job else 'failed'}")
        logger.info(f"Evening job: {evening_job.name if evening_job else 'failed'}")

        global _last_scheduled_sent_at, _last_scheduled_texts
        _last_scheduled_sent_at.clear()
        _last_scheduled_texts.clear()

        if GROUP_CHAT_ID:
            try:
                await asyncio.sleep(5)
                if datetime.now(tz).timestamp() - now.timestamp() < 30:
                    startup_texts = [
                        "–°–∞–º—É–∏–ª –≤ —Å–µ—Ç–∏. –†–µ–∂–∏–º –Ω–∞–±–ª—é–¥–µ–Ω–∏—è.",
                        "–°–∏—Å—Ç–µ–º–∞ –∞–∫—Ç–∏–≤–Ω–∞. –í—Å–µ –¥–∞—Ç—á–∏–∫–∏ –≤ –Ω–æ—Ä–º–µ.",
                        "–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ü—Ä–∏—Å—Ç—É–ø–∞—é –∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥—É.",
                    ]

                    await application.bot.send_message(
                        chat_id=int(GROUP_CHAT_ID),
                        text=random.choice(startup_texts)
                    )
                    logger.info("Startup message sent.")
            except Exception as e:
                logger.error(f"Error sending startup message: {e}")

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–¥–∞—á
job_manager = JobManager()


# ---------- ERROR HANDLING ----------

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫."""
    logger.error(f"Exception while handling an update: {context.error}")

    if ADMIN_CHAT_ID:
        try:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–æ—Ç–µ:\n{type(context.error).__name__}: {context.error}"
            await context.bot.send_message(
                chat_id=int(ADMIN_CHAT_ID),
                text=error_msg[:4000]
            )
        except Exception as e:
            logger.error(f"Failed to send error to admin: {e}")


# ---------- MAIN APP ----------

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞."""
    if not TOKEN:
        raise RuntimeError("BOT_TOKEN is not set in environment variables!")

    global _last_scheduled_sent_at, _last_scheduled_texts
    _last_scheduled_sent_at.clear()
    _last_scheduled_texts.clear()

    app = Application.builder().token(TOKEN).build()

    app.add_error_handler(error_handler)

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("chatid", chat_id))
    app.add_handler(CommandHandler("whoami", whoami))
    app.add_handler(CommandHandler("img", cmd_image))
    app.add_handler(CommandHandler("clear", cmd_clear))
    app.add_handler(CommandHandler("stats", cmd_stats))

    # –ù–æ–≤–æ–µ: /today
    app.add_handler(CommandHandler("today", cmd_today))

    app.add_handler(
        MessageHandler(
            filters.TEXT & filters.ChatType.PRIVATE & ~filters.COMMAND,
            echo_private,
        )
    )

    app.add_handler(
        MessageHandler(
            filters.TEXT & filters.ChatType.GROUPS & ~filters.COMMAND,
            handle_group_message,
        )
    )

    async def post_init(application: Application):
        """–§—É–Ω–∫—Ü–∏—è, –≤—ã–∑—ã–≤–∞–µ–º–∞—è –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ—Ç–∞."""
        logger.info("Bot initialized, setting up jobs...")
        await job_manager.setup_jobs(application)
        logger.info("Bot is ready!")

    app.post_init = post_init

    async def shutdown(application: Application):
        """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã."""
        logger.info("Shutting down bot...")
        if client:
            await client.close()
        logger.info("Bot shutdown complete.")

    app.post_shutdown = shutdown

    logger.info("Bot starting...")

    app.run_polling(
        drop_pending_updates=True,
        allowed_updates=Update.ALL_TYPES,
        close_loop=False,
    )


if __name__ == "__main__":
    main()

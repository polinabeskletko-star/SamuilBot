import os
import re
import json
import random
import asyncio
import logging
from datetime import datetime, time, date
from collections import defaultdict, deque
from typing import Dict, List, Tuple, Optional, Any
import uuid

import pytz
import httpx
from openai import AsyncOpenAI
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# ==== SETTINGS & ENV ====

TOKEN = os.environ.get("BOT_TOKEN")
GROUP_CHAT_ID = os.environ.get("GROUP_CHAT_ID")  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "-1001234567890"
TIMEZONE = os.environ.get("BOT_TZ", "Australia/Brisbane")

# Telegram user IDs
TARGET_USER_ID = int(os.environ.get("TARGET_USER_ID", "0"))   # –ú–∞–∫—Å–∏–º

# Optional: –∫—É–¥–∞ —Å–ª–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ–±–µ –≤ –ª–∏—á–∫—É)
ADMIN_CHAT_ID = os.environ.get("ADMIN_CHAT_ID")

# OpenAI
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")

client: Optional[AsyncOpenAI] = None
if OPENAI_API_KEY:
    client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# OpenWeather
OPENWEATHER_API_KEY = os.environ.get("OPENWEATHER_API_KEY")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ---------- GLOBAL STATE ----------

# –ü–æ–º–æ–≥–∞–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –ø–æ–Ω—è—Ç—å, –æ–¥–∏–Ω –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞–±–æ—Ç–∞–µ—Ç
INSTANCE_TAG = os.environ.get("INSTANCE_TAG") or str(uuid.uuid4())[:8]

dialog_history: Dict[Tuple[int, int], List[Dict[str, str]]] = defaultdict(list)
daily_summary_log: Dict[str, List[str]] = defaultdict(list)

# job_name -> datetime last_sent_at (tz-aware)
_last_scheduled_sent_at: Dict[str, datetime] = {}
# job_name -> deque –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
_last_scheduled_texts: Dict[str, deque] = defaultdict(lambda: deque(maxlen=5))

_last_maxim_replies: deque = deque(maxlen=8)

_weather_cache: Dict[str, Tuple[Dict[str, Any], datetime]] = {}
WEATHER_CACHE_TTL = 300  # 5 –º–∏–Ω—É—Ç

_openai_cache: Dict[str, Tuple[str, datetime]] = {}
OPENAI_CACHE_TTL = 600  # 10 –º–∏–Ω—É—Ç

# /today output cache (–≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç)
_onthisday_cache: Dict[str, Tuple[str, datetime]] = {}
ONTHISDAY_CACHE_TTL = 6 * 3600  # 6 —á–∞—Å–æ–≤

# onthisday structured cache (—Å–ø–∏—Å–æ–∫ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤/—Å–æ–±—ã—Ç–∏–π)
_onthisday_struct_cache: Dict[str, Tuple[Dict[str, Any], datetime]] = {}

# —Ñ–ª–∞–≥–∏ "–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–µ–≥–æ–¥–Ω—è" –¥–ª—è scheduled (–≤ —Ä–∞–º–∫–∞—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞)
_sent_day_flags: Dict[str, datetime] = {}

# ---------- HELPERS ----------

def get_tz() -> pytz.BaseTzInfo:
    return pytz.timezone(TIMEZONE)


async def log_to_admin(context: ContextTypes.DEFAULT_TYPE, message: str):
    if ADMIN_CHAT_ID:
        try:
            await context.bot.send_message(chat_id=int(ADMIN_CHAT_ID), text=message)
        except Exception as e:
            logger.error(f"Failed to send admin log: {e}")


def generate_cache_key(messages: List[Dict[str, str]], max_tokens: int, temperature: float) -> str:
    import hashlib
    key_str = f"{json.dumps(messages, sort_keys=True)}:{max_tokens}:{temperature}"
    return hashlib.md5(key_str.encode()).hexdigest()


async def call_openai_chat(
    messages: List[Dict[str, str]],
    max_tokens: int = 120,
    temperature: float = 0.7,
    use_cache: bool = True,
) -> Tuple[Optional[str], Optional[str]]:
    if client is None:
        return None, "OpenAI client is not configured (no API key)."

    if use_cache:
        cache_key = generate_cache_key(messages, max_tokens, temperature)
        cached_data = _openai_cache.get(cache_key)
        if cached_data:
            response, timestamp = cached_data
            if (datetime.now() - timestamp).total_seconds() < OPENAI_CACHE_TTL:
                return response, None

    try:
        resp = await client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
        )
        text = (resp.choices[0].message.content or "").strip()
        if not text:
            return None, "Empty response from OpenAI."

        if use_cache:
            cache_key = generate_cache_key(messages, max_tokens, temperature)
            _openai_cache[cache_key] = (text, datetime.now())

        return text, None
    except Exception as e:
        err = f"Error calling OpenAI: {e}"
        logger.error(err)
        return None, err


async def generate_image_from_prompt(prompt: str) -> Tuple[Optional[str], Optional[str]]:
    if client is None:
        return None, "OpenAI client is not configured (no API key)."

    try:
        resp = await client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            n=1,
            size="1024x1024",
            quality="standard",
        )
        image_url = resp.data[0].url
        return image_url, None
    except Exception as e:
        err = f"Error calling OpenAI Images: {e}"
        logger.error(err)
        return None, err


# ---------- WEATHER HELPERS ----------

async def fetch_weather_for_city(city_query: str, use_cache: bool = True) -> Optional[Dict[str, Any]]:
    if not OPENWEATHER_API_KEY:
        return None

    if use_cache:
        cached_data = _weather_cache.get(city_query)
        if cached_data:
            data, timestamp = cached_data
            if (datetime.now() - timestamp).total_seconds() < WEATHER_CACHE_TTL:
                return data

    url = "https://api.openweathermap.org/data/2.5/weather"
    params = {
        "q": city_query,
        "appid": OPENWEATHER_API_KEY,
        "units": "metric",
        "lang": "ru",
    }

    try:
        async with httpx.AsyncClient(timeout=10) as http_client:
            resp = await http_client.get(url, params=params)

        if resp.status_code != 200:
            logger.error(f"OpenWeather error for '{city_query}': {resp.status_code} {resp.text}")
            return None

        data = resp.json()
        main = data.get("main", {})
        weather_list = data.get("weather", [])
        weather_desc = weather_list[0]["description"] if weather_list else "–±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"

        result = {
            "city": data.get("name", city_query),
            "country": data.get("sys", {}).get("country", ""),
            "temp": main.get("temp"),
            "feels_like": main.get("feels_like"),
            "humidity": main.get("humidity"),
            "description": weather_desc,
        }

        if use_cache:
            _weather_cache[city_query] = (result, datetime.now())

        return result
    except Exception as e:
        logger.error(f"Error fetching weather: {e}")
        return None


def detect_weather_city_from_text(text: str) -> Optional[str]:
    t = text.lower()
    city_mapping = {
        "–∫–∞–ª—É–≥–µ": "Kaluga,ru",
        "–∫–∞–ª—É–≥–∞": "Kaluga,ru",
        "kaluga": "Kaluga,ru",
        "–±—Ä–∏—Å–±–µ–Ω–µ": "Brisbane,au",
        "–±—Ä–∏—Å–±–µ–Ω": "Brisbane,au",
        "brisbane": "Brisbane,au",
        "–º–æ—Å–∫–≤–µ": "Moscow,ru",
        "–º–æ—Å–∫–≤–∞": "Moscow,ru",
        "moscow": "Moscow,ru",
        "–ø–∏—Ç–µ—Ä–µ": "Saint Petersburg,ru",
        "–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "Saint Petersburg,ru",
        "—Å–ø–±": "Saint Petersburg,ru",
    }

    for russian, english in city_mapping.items():
        if russian in t:
            return english

    m = re.search(r"\b(?:–≤|–≤ –≥–æ—Ä–æ–¥–µ)\s+([–ê-–Ø–∞-—èA-Za-z\-]+)", t)
    if m:
        return m.group(1)
    return None


def format_weather_for_prompt(info: Dict[str, Any]) -> str:
    if not info:
        return ""
    parts = []
    city = info.get("city")
    country = info.get("country")
    temp = info.get("temp")
    feels = info.get("feels_like")
    hum = info.get("humidity")
    desc = info.get("description")

    if city:
        location = f"{city}, {country}" if country else str(city)
        parts.append(f"–ü–æ–≥–æ–¥–∞ –≤ {location}")
    if desc:
        parts.append(f"—Å–µ–π—á–∞—Å {desc}")
    if temp is not None:
        parts.append(f"—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ {round(temp)}¬∞C")
    if feels is not None and temp is not None and abs(feels - temp) > 1:
        parts.append(f"–æ—â—É—â–∞–µ—Ç—Å—è –∫–∞–∫ {round(feels)}¬∞C")
    if hum is not None:
        parts.append(f"–≤–ª–∞–∂–Ω–æ—Å—Ç—å {hum}%")

    return ", ".join(parts)


# ---------- TODAY: HOLIDAYS & EVENTS (Wikimedia On This Day) ----------

def _smart_truncate(text: str, max_len: int = 3900) -> str:
    """
    –£–º–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –ø–æ–¥ –ª–∏–º–∏—Ç Telegram (4096).
    –°—Ç–∞—Ä–∞–µ–º—Å—è —Ä–µ–∑–∞—Ç—å –ø–æ –≥—Ä–∞–Ω–∏—Ü–µ –ø—É–Ω–∫—Ç–∞/—Å—Ç—Ä–æ–∫–∏/—Å–ª–æ–≤–∞, –∞ –Ω–µ –ø–æ—Å—Ä–µ–¥–∏.
    """
    if not text or len(text) <= max_len:
        return text

    cut = text[:max_len]

    # 1) –ü–æ –Ω–∞—á–∞–ª—É —Å–ª–µ–¥—É—é—â–µ–≥–æ –±—É–ª–ª–µ—Ç–∞
    idx = cut.rfind("\n‚Ä¢ ")
    if idx > 0 and idx > max_len * 0.6:
        cut = cut[:idx]
    else:
        # 2) –ü–æ —Å—Ç—Ä–æ–∫–µ
        idx = cut.rfind("\n")
        if idx > 0 and idx > max_len * 0.6:
            cut = cut[:idx]
        else:
            # 3) –ü–æ —Å–ª–æ–≤—É
            idx = cut.rfind(" ")
            if idx > 0 and idx > max_len * 0.6:
                cut = cut[:idx]

    return cut.rstrip() + "\n‚Ä¶"


async def fetch_onthisday_struct_ru(d: date, use_cache: bool = True) -> Optional[Dict[str, Any]]:
    """
    –¢—è–Ω–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ '–≤ —ç—Ç–æ—Ç –¥–µ–Ω—å' (ru) –∏ –≤—ã–±–∏—Ä–∞–µ–º
    –Ω–µ–±–æ–ª—å—à—É—é –≤—ã–±–æ—Ä–∫—É –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –∏ —Å–æ–±—ã—Ç–∏–π.
    """
    key = d.isoformat()
    now = datetime.now()

    if use_cache:
        cached = _onthisday_struct_cache.get(key)
        if cached:
            data, ts = cached
            if (now - ts).total_seconds() < ONTHISDAY_CACHE_TTL:
                return data

    mm = f"{d.month:02d}"
    dd = f"{d.day:02d}"
    url = f"https://api.wikimedia.org/feed/v1/wikipedia/ru/onthisday/all/{mm}/{dd}"
    headers = {"User-Agent": f"SamuilBot/1.0 (telegram-bot; onthisday; {INSTANCE_TAG})"}

    try:
        async with httpx.AsyncClient(timeout=12) as http_client:
            resp = await http_client.get(url, headers=headers)

        if resp.status_code != 200:
            logger.error(f"OnThisDay API error: {resp.status_code} {resp.text[:200]}")
            return None

        raw = resp.json()

        def _pick(arr: List[Dict[str, Any]], n: int, require_year: bool = False) -> List[Dict[str, Any]]:
            items = list(arr or [])
            random.shuffle(items)
            out = []
            for it in items:
                if require_year and "year" not in it:
                    continue
                txt = (it.get("text") or "").strip()
                if not txt:
                    continue
                # –ª—ë–≥–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤
                if len(txt) > 240:
                    continue
                out.append(it)
                if len(out) >= n:
                    break
            return out

        # –î–ª—è "–ø–æ–≤–æ–¥–∞" –ª—É—á—à–µ –º–µ–Ω—å—à–µ, –Ω–æ —Å–æ—á–Ω–µ–µ
        holidays = _pick(raw.get("holidays", []), n=3, require_year=False)
        events = _pick(raw.get("events", []), n=5, require_year=True)

        data_out = {
            "date": f"{dd}.{mm}",
            "holidays": [{"text": (h.get("text") or "").strip()} for h in holidays],
            "events": [{"year": e.get("year"), "text": (e.get("text") or "").strip()} for e in events],
        }

        _onthisday_struct_cache[key] = (data_out, now)
        return data_out

    except Exception as e:
        logger.error(f"Error fetching onthisday struct: {e}")
        return None


async def fetch_onthisday_ru(d: date, use_cache: bool = True, max_len: int = 3900) -> Optional[str]:
    """
    –°—Ç–∞—Ä—ã–π /today: –ø—Ä–∞–∑–¥–Ω–∏–∫–∏+—Å–æ–±—ã—Ç–∏—è —Å–ø–∏—Å–∫–æ–º.
    """
    key = d.isoformat()
    now = datetime.now()

    if use_cache:
        cached = _onthisday_cache.get(key)
        if cached:
            text, ts = cached
            if (now - ts).total_seconds() < ONTHISDAY_CACHE_TTL:
                return text

    data = await fetch_onthisday_struct_ru(d, use_cache=use_cache)
    if not data:
        return None

    ddmm = data["date"]
    holidays = data.get("holidays", [])
    events = data.get("events", [])

    lines: List[str] = []
    title = f"üìÖ –°–µ–≥–æ–¥–Ω—è ({ddmm})"

    if holidays:
        lines.append("–ü—Ä–∞–∑–¥–Ω–∏–∫–∏:")
        for h in holidays:
            lines.append(f"‚Ä¢ {h.get('text','').strip()}")

    if events:
        if holidays:
            lines.append("")
        lines.append("–°–æ–±—ã—Ç–∏—è:")
        for e in events[:6]:
            y = e.get("year")
            t = (e.get("text") or "").strip()
            if y and t:
                lines.append(f"‚Ä¢ {y}: {t}")
            elif t:
                lines.append(f"‚Ä¢ {t}")

    if not holidays and not events:
        lines.append("–°–µ–≥–æ–¥–Ω—è –±–µ–∑ —è—Ä–∫–∏—Ö –ø—É–Ω–∫—Ç–æ–≤ –ø–æ –±–∞–∑–µ. –ó–Ω–∞—á–∏—Ç, –º–æ–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å —Å–≤–æ–π –ø–æ–≤–æ–¥ üôÇ")

    text_out = title + "\n" + "\n".join(lines)
    text_out = _smart_truncate(text_out, max_len=max_len)

    _onthisday_cache[key] = (text_out, now)
    return text_out


async def cmd_today(update: Update, context: ContextTypes.DEFAULT_TYPE):
    tz = get_tz()
    now = datetime.now(tz)
    text = await fetch_onthisday_ru(now.date())
    if not text:
        await update.message.reply_text("–ù–µ —Å–º–æ–≥ –¥–æ—Å—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
        return
    await update.message.reply_text(text)


# ---------- NEW: "–ü–û–í–û–î –ü–û–î–ù–Ø–¢–¨ –ë–û–ö–ê–õ" ----------

MAX_TOAST_TOKENS = 220  # —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–µ–∑–∞–ª–æ –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ

def _format_items_for_prompt(data: Dict[str, Any]) -> str:
    ddmm = data.get("date", "")
    holidays = data.get("holidays", [])
    events = data.get("events", [])

    # –°–æ–±–µ—Ä—ë–º 2-4 –ø—É–Ω–∫—Ç–∞ –≤—Å–µ–≥–æ
    pool: List[str] = []
    for h in holidays:
        t = (h.get("text") or "").strip()
        if t:
            pool.append(f"–ü—Ä–∞–∑–¥–Ω–∏–∫: {t}")

    for e in events:
        y = e.get("year")
        t = (e.get("text") or "").strip()
        if t and y:
            pool.append(f"–°–æ–±—ã—Ç–∏–µ: {y} ‚Äî {t}")
        elif t:
            pool.append(f"–°–æ–±—ã—Ç–∏–µ: {t}")

    random.shuffle(pool)
    chosen = pool[:4] if len(pool) >= 4 else pool[:max(2, len(pool))]

    # fallback –µ—Å–ª–∏ –ø—É—Å—Ç–æ
    if not chosen:
        chosen = ["–°–µ–≥–æ–¥–Ω—è –±–∞–∑–∞ —Å–∫—É—á–∞–µ—Ç. –ü—Ä–∏–¥—É–º–∞–π –ø–æ–≤–æ–¥ —Å–∞–º."]

    joined = "\n".join(f"- {x}" for x in chosen)
    return f"–î–∞—Ç–∞: {ddmm}\n–§–∞–∫—Ç—ã –¥–Ω—è:\n{joined}"


async def generate_toast_from_onthisday(now: datetime) -> Optional[str]:
    """
    –î–µ–ª–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π "–ø–æ–≤–æ–¥ –ø–æ–¥–Ω—è—Ç—å –±–æ–∫–∞–ª (–∏–ª–∏ —á–∞–π)" –≤ —Å—Ç–∏–ª–µ –°–∞–º—É–∏–ª–∞.
    –í–∞–∂–Ω–æ: –±–µ–∑ –ø—Ä—è–º–æ–≥–æ –ø—Ä–∏–∑—ã–≤–∞ –∫ –∑–ª–æ—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—é ‚Äî –ª—ë–≥–∫–∞—è —à—É—Ç–∫–∞ –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –±–µ–∑ –∞–ª–∫–æ–≥–æ–ª—è.
    """
    data = await fetch_onthisday_struct_ru(now.date(), use_cache=True)
    if not data:
        return None

    system_prompt = (
        "–¢—ã ‚Äî –°–∞–º—É–∏–ª, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π, –Ω–æ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç.\n"
        "–ì–æ–≤–æ—Ä–∏—à—å –ø–æ-—Ä—É—Å—Å–∫–∏, –Ω–∞ '—Ç—ã'.\n"
        "–ò—Ä–æ–Ω–∏—á–Ω—ã–π, –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, –ù–ï –≥—Ä—É–±—ã–π.\n"
        "–≠–º–æ–¥–∑–∏: –º–∞–∫—Å–∏–º—É–º 1.\n"
        "–ü–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π.\n"
        "–¢–µ–º–∞: ¬´–ø–æ–≤–æ–¥ –ø–æ–¥–Ω—è—Ç—å –±–æ–∫–∞–ª¬ª –ø–æ —Å–æ–±—ã—Ç–∏—è–º –¥–Ω—è.\n"
        "–í–ê–ñ–ù–û: –Ω–µ –ø–æ–æ—â—Ä—è–π –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–µ –ø—å—è–Ω—Å—Ç–≤–æ. –§–æ—Ä–º—É–ª–∏—Ä—É–π –∫–∞–∫ ¬´–ø–æ–¥–Ω—è—Ç—å –±–æ–∫–∞–ª (–∏–ª–∏ —á–∞–π/–±–µ–∑–∞–ª–∫)¬ª, –¥–æ–±–∞–≤—å –º—è–≥–∫–æ–µ ¬´–±–µ–∑ —Ñ–∞–Ω–∞—Ç–∏–∑–º–∞¬ª.\n"
    )

    facts = _format_items_for_prompt(data)

    user_prompt = (
        f"{facts}\n\n"
        "–ó–∞–¥–∞–Ω–∏–µ:\n"
        "1) –í—ã–±–µ—Ä–∏ 2‚Äì3 —Å–∞–º—ã—Ö –∑–∞–±–∞–≤–Ω—ã—Ö/–∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã—Ö –ø—É–Ω–∫—Ç–∞ –∏–∑ —Ñ–∞–∫—Ç–æ–≤.\n"
        "2) –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π ¬´–ü–æ–≤–æ–¥ –¥–Ω—è¬ª –≤ 4‚Äì7 —Å—Ç—Ä–æ–∫, –∫–∞–∫ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ.\n"
        "3) –°—Ç—Ä—É–∫—Ç—É—Ä–∞:\n"
        "   - –ó–∞–≥–æ–ª–æ–≤–æ–∫: ¬´üç∑ –ü–æ–≤–æ–¥ –¥–Ω—è (–∏–ª–∏ —á–∞–π)¬ª\n"
        "   - 2‚Äì3 –±—É–ª–ª–µ—Ç–∞ —Å —Ñ–∞–∫—Ç–∞–º–∏, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–º–µ—à–Ω–æ –∏ –ª–∞–∫–æ–Ω–∏—á–Ω–æ\n"
        "   - 1 –∫–æ—Ä–æ—Ç–∫–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Ñ—Ä–∞–∑–∞-–∏—Ä–æ–Ω–∏—è\n"
        "   - –í –∫–æ–Ω—Ü–µ: ¬´–±–µ–∑ —Ñ–∞–Ω–∞—Ç–∏–∑–º–∞¬ª –∏–ª–∏ ¬´–º–æ–∂–Ω–æ –±–µ–∑–∞–ª–∫¬ª (1 —Ä–∞–∑)\n"
        "4) –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã, –æ–ø–∏—Ä–∞–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –¥–∞–Ω–Ω—ã–µ –≤—ã—à–µ.\n"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    text, err = await call_openai_chat(
        messages, max_tokens=MAX_TOAST_TOKENS, temperature=0.95, use_cache=False
    )
    if not text:
        return None

    return _smart_truncate(text.strip(), max_len=3600)


async def cmd_toast(update: Update, context: ContextTypes.DEFAULT_TYPE):
    tz = get_tz()
    now = datetime.now(tz)
    toast = await generate_toast_from_onthisday(now)
    if not toast:
        await update.message.reply_text("–°–µ–≥–æ–¥–Ω—è –ø–æ–≤–æ–¥ –Ω–µ –Ω–∞—à—ë–ª—Å—è. –ó–Ω–∞—á–∏—Ç, —Ç—ã –∂–∏–≤—ë—à—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ.")
        return
    await update.message.reply_text(toast)


# ---------- AI GENERATORS ----------

MAX_QA_TOKENS = 160
MAX_MAXIM_REPLY_TOKENS = 70
MAX_SCHEDULED_TOKENS = 90

def get_time_context(hour: int) -> str:
    if hour < 6:
        return "–ù–æ—á—å."
    elif hour < 12:
        return "–£—Ç—Ä–æ."
    elif hour < 17:
        return "–î–µ–Ω—å."
    elif hour < 22:
        return "–í–µ—á–µ—Ä."
    else:
        return "–ü–æ–∑–¥–Ω–∏–π –≤–µ—á–µ—Ä."


def build_samuil_system_prompt(include_maxim_context: bool = False) -> str:
    base = (
        "–¢—ã ‚Äî –°–∞–º—É–∏–ª, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π, –Ω–æ –≤ —Ü–µ–ª–æ–º –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç.\n"
        "–ì–æ–≤–æ—Ä–∏—à—å –ø–æ-—Ä—É—Å—Å–∫–∏, –Ω–∞ '—Ç—ã'.\n"
        "–ò—Ä–æ–Ω–∏—á–Ω—ã–π, –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, –∏–Ω–æ–≥–¥–∞ —Å–ª–µ–≥–∫–∞ –∫–æ–ª–∫–∏–π, –Ω–æ –ù–ï –≥—Ä—É–±—ã–π –∏ –ù–ï —Ç–æ–∫—Å–∏—á–Ω—ã–π.\n"
        "–ü–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ –≤ —á–∞—Ç–µ.\n"
        "–≠–º–æ–¥–∑–∏: —Ä–µ–¥–∫–æ, –º–∞–∫—Å–∏–º—É–º 0‚Äì1.\n"
        "–ò–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–æ–≤ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫.\n"
    )
    if not include_maxim_context:
        return base

    maxim_ctx = (
        "\n=== –ö–û–ù–¢–ï–ö–°–¢ –ü–†–û –ú–ê–ö–°–ò–ú–ê ===\n"
        "–§–∞–∫—Ç—ã (–∏—Å–ø–æ–ª—å–∑—É–π 1‚Äì2 –∑–∞ —Ä–∞–∑, –ù–ï —Å–ø–∏—Å–∫–æ–º):\n"
        "- –ø–æ—á—Ç–∏ 40, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—ã–ª –∂–µ–Ω–∞—Ç\n"
        "- –º–∞–º–∞ –∂–¥—ë—Ç –≤–Ω—É–∫–æ–≤, –æ–Ω –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π\n"
        "- –ñ–µ–ª–Ω–∏–Ω —É–µ—Ö–∞–ª, –∫–æ–º–ø–∞–Ω–∏–∏ –º–µ–Ω—å—à–µ\n"
        "- —Å—á–∏—Ç–∞–µ—Ç —Å–µ–±—è –≥–µ–Ω–∏–∞–ª—å–Ω—ã–º –∏ –∏–¥–µ–∞–ª—å–Ω—ã–º, –Ω–æ –æ–¥–∏–Ω–æ–∫\n"
        "- —Ö–æ—á–µ—Ç –¥–µ–≤—É—à–∫—É –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–æ–ª–æ–∂–µ\n"
        "–ò—Ä–æ–Ω–∏—è –ª—ë–≥–∫–∞—è, –∏–Ω—Ç–µ–ª–ª–∏–≥–µ–Ω—Ç–Ω–∞—è.\n"
    )
    return base + maxim_ctx


def _normalize_text_for_dedupe(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip().lower())


def _should_dedupe_scheduled_send(job_name: str, now: datetime, text: str) -> bool:
    norm = _normalize_text_for_dedupe(text)
    if not norm:
        return False

    last_at = _last_scheduled_sent_at.get(job_name)
    if last_at is not None:
        if abs((now - last_at).total_seconds()) < 600:
            logger.info(f"Dedupe: too soon since last send for {job_name}")
            return True

    for prev in _last_scheduled_texts[job_name]:
        prev_norm = _normalize_text_for_dedupe(prev)
        if norm == prev_norm:
            logger.info(f"Dedupe: duplicate text detected for {job_name}")
            return True

        if len(norm) > 20 and len(prev_norm) > 20:
            words_current = set(norm.split())
            words_prev = set(prev_norm.split())
            similarity = len(words_current & words_prev) / max(len(words_current), len(words_prev))
            if similarity > 0.8:
                logger.info(f"Dedupe: high similarity ({similarity:.0%}) for {job_name}")
                return True

    return False


def _record_scheduled_send(job_name: str, now: datetime, text: str) -> None:
    _last_scheduled_sent_at[job_name] = now
    _last_scheduled_texts[job_name].append(text)


async def generate_sarcastic_reply_for_maxim(now: datetime, user_text: str) -> Tuple[Optional[str], Optional[str]]:
    weekday_names = ["–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫","–≤—Ç–æ—Ä–Ω–∏–∫","—Å—Ä–µ–¥–∞","—á–µ—Ç–≤–µ—Ä–≥","–ø—è—Ç–Ω–∏—Ü–∞","—Å—É–±–±–æ—Ç–∞","–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]
    weekday_name = weekday_names[now.weekday()]
    time_str = now.strftime("%H:%M")
    time_context = get_time_context(now.hour)

    system_prompt = build_samuil_system_prompt(include_maxim_context=True)

    last_replies = "\n".join(f"- {x}" for x in list(_last_maxim_replies)[-6:]) or "- (–Ω–µ—Ç)"
    user_prompt = (
        f"–î–µ–Ω—å: {weekday_name}, –≤—Ä–µ–º—è: {time_str}. {time_context}\n"
        f"–°–æ–æ–±—â–µ–Ω–∏–µ –ú–∞–∫—Å–∏–º–∞: ¬´{user_text}¬ª\n\n"
        f"–ù–ï –ø–æ–≤—Ç–æ—Ä—è–π –¥–æ—Å–ª–æ–≤–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Ç–≤–µ—Ç—ã –°–∞–º—É–∏–ª–∞:\n{last_replies}\n\n"
        "–ó–∞–¥–∞–Ω–∏–µ: –ø—Ä–∏–¥—É–º–∞–π –û–ß–ï–ù–¨ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (–æ–¥–Ω–∞ —Ñ—Ä–∞–∑–∞ –∏–ª–∏ 1‚Äì2 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).\n"
        "–ë–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π.\n"
    )

    messages = [{"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}]

    text, err = await call_openai_chat(
        messages, max_tokens=MAX_MAXIM_REPLY_TOKENS, temperature=0.95, use_cache=False
    )
    if text:
        _last_maxim_replies.append(text)
    return text, err


async def generate_samuil_answer(
    now: datetime,
    chat_id: int,
    user_id: int,
    user_text: str,
    weather_info: Optional[Dict[str, Any]] = None,
) -> Tuple[Optional[str], Optional[str]]:
    weekday_names = ["–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫","–≤—Ç–æ—Ä–Ω–∏–∫","—Å—Ä–µ–¥–∞","—á–µ—Ç–≤–µ—Ä–≥","–ø—è—Ç–Ω–∏—Ü–∞","—Å—É–±–±–æ—Ç–∞","–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]
    weekday_name = weekday_names[now.weekday()]
    time_str = now.strftime("%H:%M")

    text_lower = user_text.lower()
    include_maxim_context = (user_id == TARGET_USER_ID) or ("–º–∞–∫—Å–∏–º" in text_lower)

    system_prompt = build_samuil_system_prompt(include_maxim_context=include_maxim_context)
    time_context = get_time_context(now.hour)

    extra_context_parts = [
        f"–°–µ–≥–æ–¥–Ω—è {weekday_name}. {time_context} –°–µ–π—á–∞—Å {time_str}.",
        "–¢—ã –≤ –≥—Ä—É–ø–ø–æ–≤–æ–º —á–∞—Ç–µ. –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.",
    ]
    if weather_info is not None:
        extra_context_parts.append(f"–¢–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≥–æ–¥–µ (–∫–∞–∫ —Ñ–∞–∫—Ç): {format_weather_for_prompt(weather_info)}")

    key = (chat_id, user_id)
    history = dialog_history[key]

    messages: List[Dict[str, str]] = [{"role": "system", "content": system_prompt}]
    messages.append({"role": "user", "content": " ".join(extra_context_parts)})

    if history:
        messages.extend(history[-4:])

    messages.append({"role": "user", "content": user_text})

    if "?" in user_text:
        messages.append({"role": "system", "content": "–ï—Å–ª–∏ —ç—Ç–æ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ (2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."})
    else:
        messages.append({"role": "system", "content": "–ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."})

    text, err = await call_openai_chat(messages, max_tokens=MAX_QA_TOKENS, temperature=0.85, use_cache=False)

    if text is not None:
        history.append({"role": "user", "content": user_text})
        history.append({"role": "assistant", "content": text})
        dialog_history[key] = history[-20:]

    return text, err


# ---------- COMMAND HANDLERS ----------

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_type = update.effective_chat.type
    if chat_type == "private":
        await update.message.reply_text(
            "–ü—Ä–∏–≤–µ—Ç! –Ø –°–∞–º—É–∏–ª ü§ñ\n"
            "–í –≥—Ä—É–ø–ø–µ –∏–Ω–æ–≥–¥–∞ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é –ú–∞–∫—Å–∏–º–∞, "
            "–∞ –µ—Å–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å '–°–∞–º—É–∏–ª' –∏–ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å —Ä–µ–ø–ª–∞–µ–º ‚Äî –æ—Ç–≤–µ—á—É.\n"
            "–ö–∞—Ä—Ç–∏–Ω–∫–∏: /img <–∑–∞–ø—Ä–æ—Å>. –°–æ–±—ã—Ç–∏—è –¥–Ω—è: /today. –ü–æ–≤–æ–¥ –¥–Ω—è: /toast."
        )
    else:
        await update.message.reply_text(
            "–Ø –°–∞–º—É–∏–ª. –ó–æ–≤–∏ –ø–æ –∏–º–µ–Ω–∏ (–∏–ª–∏ —Ä–µ–ø–ª–∞–µ–º) ‚Äî –æ—Ç–≤–µ—á—É. /today ‚Äî —á—Ç–æ —Å–µ–≥–æ–¥–Ω—è –∑–∞ –¥–µ–Ω—å. /toast ‚Äî –ø–æ–≤–æ–¥ –¥–Ω—è."
        )


async def chat_id_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cid = update.effective_chat.id
    await update.message.reply_text(f"Chat ID for this chat: `{cid}`", parse_mode="Markdown")


async def whoami(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    await update.message.reply_text(
        f"Your user ID: `{user.id}`\nUsername: @{user.username}", parse_mode="Markdown"
    )


async def echo_private(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_chat.type != "private":
        return
    text = update.message.text or ""
    await update.message.reply_text(f"–¢—ã –Ω–∞–ø–∏—Å–∞–ª: {text}")


async def cmd_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if client is None:
        await update.message.reply_text("–£ –º–µ–Ω—è –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω OpenAI API, –∫–∞—Ä—Ç–∏–Ω–∫—É —Å–¥–µ–ª–∞—Ç—å –Ω–µ –º–æ–≥—É.")
        return
    args = context.args
    if not args:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä: /img –∫–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ")
        return

    prompt = " ".join(args).strip()
    if len(prompt) > 1000:
        await update.message.reply_text("–ó–∞–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –£–∫–æ—Ä–æ—Ç–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")
        return

    status_msg = await update.message.reply_text("üé® –°–æ–∑–¥–∞—é –∫–∞—Ä—Ç–∏–Ω–∫—É...")
    img_url, err = await generate_image_from_prompt(prompt)
    if img_url is None:
        logger.error(f"Image generation error: {err}")
        await status_msg.edit_text("–ù–µ –≤—ã—à–ª–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É. –ü–æ–ø—Ä–æ–±—É–π –ø—Ä–æ—â–µ –∑–∞–ø—Ä–æ—Å.")
        return

    try:
        await status_msg.delete()
        await update.message.chat.send_photo(
            photo=img_url,
            caption=f"üé® {prompt[:100]}{'...' if len(prompt) > 100 else ''}",
        )
    except Exception as e:
        logger.error(f"Error sending image: {e}")
        await update.message.reply_text("–ö–∞—Ä—Ç–∏–Ω–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞—Å—å, –Ω–æ —è –Ω–µ —Å–º–æ–≥ –µ—ë –æ—Ç–ø—Ä–∞–≤–∏—Ç—å.")


async def cmd_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    key = (update.effective_chat.id, update.effective_user.id)
    dialog_history[key] = []
    await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")


async def cmd_stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –°–∞–º—É–∏–ª–∞:\n"
        f"‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {len(dialog_history)}\n"
        f"‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {sum(len(h) for h in dialog_history.values())}\n"
        f"‚Ä¢ –ö—ç—à –ø–æ–≥–æ–¥—ã: {len(_weather_cache)}\n"
        f"‚Ä¢ –ö—ç—à OpenAI: {len(_openai_cache)}\n"
        f"‚Ä¢ –ö—ç—à /today: {len(_onthisday_cache)}\n"
        f"‚Ä¢ –ö—ç—à /today struct: {len(_onthisday_struct_cache)}\n"
        f"‚Ä¢ INSTANCE_TAG: {INSTANCE_TAG}"
    )


# ---------- GROUP MESSAGE HANDLER ----------

def _looks_like_image_request(text_lower: str) -> bool:
    keywords = ["–∫–∞—Ä—Ç–∏–Ω–∫", "—Ñ–æ—Ç–æ", "—Ñ–æ—Ç–∫—É", "–≥–∏—Ñ", "gif", "–º–µ–º", "picture", "image"]
    verbs = ["—Å–¥–µ–ª–∞–π", "–Ω–∞—Ä–∏—Å—É–π", "–Ω–∞–π–¥–∏", "–ø–æ–∫–∞–∂–∏", "–ø—Ä–∏–¥—É–º–∞–π"]
    return any(k in text_lower for k in keywords) and any(v in text_lower for v in verbs)


def _clean_prompt_for_image(text: str) -> str:
    patterns = [
        (r"\b—Å–∞–º—É–∏–ª\b", ""),
        (r"(—Å–¥–µ–ª–∞–π|–Ω–∞—Ä–∏—Å—É–π|–Ω–∞–π–¥–∏|–ø–æ–∫–∞–∂–∏|–ø—Ä–∏–¥—É–º–∞–π)( –º–Ω–µ)?\s+(–∫–∞—Ä—Ç–∏–Ω–∫—É|–º–µ–º|–≥–∏—Ñ–∫—É|—Ñ–æ—Ç–æ)", ""),
        (r"–ø–æ–∂–∞–ª—É–π—Å—Ç–∞\b", ""),
        (r"\s+", " "),
    ]
    result = text.strip()
    for pattern, replacement in patterns:
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    return result.strip() or "—Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π –º–µ–º –ø—Ä–æ –æ–¥–∏–Ω–æ–∫–æ–≥–æ –≤–∑—Ä–æ—Å–ª–æ–≥–æ –º—É–∂—á–∏–Ω—É –ø–æ –∏–º–µ–Ω–∏ –ú–∞–∫—Å–∏–º"


async def handle_group_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    if message is None or message.text is None:
        return

    chat = message.chat
    user = message.from_user
    text = message.text.strip()

    chat_id_val = chat.id
    user_id = user.id

    # –ï—Å–ª–∏ –∑–∞–¥–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π GROUP_CHAT_ID ‚Äî —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–∞–º
    if GROUP_CHAT_ID:
        try:
            if chat_id_val != int(GROUP_CHAT_ID):
                return
        except ValueError:
            pass

    tz = get_tz()
    now = datetime.now(tz)
    today_str = now.date().isoformat()

    author_name = user.username or user.full_name or str(user_id)
    daily_summary_log[today_str].append(f"{author_name}: {text}")

    text_lower = text.lower()

    is_reply_to_bot = (
        message.reply_to_message is not None
        and message.reply_to_message.from_user is not None
        and message.reply_to_message.from_user.id == context.bot.id
    )

    # 1) –ü—Ä—è–º–æ–µ –æ–±—â–µ–Ω–∏–µ —Å –°–∞–º—É–∏–ª–æ–º
    if is_reply_to_bot or ("—Å–∞–º—É–∏–ª" in text_lower):
        # –ö–∞—Ä—Ç–∏–Ω–∫–∞ –ø–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–µ
        if _looks_like_image_request(text_lower) and client is not None:
            prompt = _clean_prompt_for_image(text)
            status_msg = await message.chat.send_message("üé® –°–æ–∑–¥–∞—é –∫–∞—Ä—Ç–∏–Ω–∫—É...")
            img_url, err = await generate_image_from_prompt(prompt)
            if img_url is None:
                await status_msg.edit_text("–ù–µ –≤—ã—à–ª–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑, –Ω–æ –ø–æ–ø—Ä–æ—â–µ.")
                return
            await status_msg.delete()
            await message.chat.send_photo(photo=img_url, caption=f"üé® {prompt[:100]}")
            return

        # –ü–æ–≥–æ–¥–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–Ω–æ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç
        weather_info = None
        if any(k in text_lower for k in ["–ø–æ–≥–æ–¥", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä", "–∂–∞—Ä–∞", "—Ö–æ–ª–æ–¥", "–¥–æ–∂–¥—å"]):
            city_query = detect_weather_city_from_text(text)
            if city_query:
                weather_info = await fetch_weather_for_city(city_query)

        ai_text, err = await generate_samuil_answer(
            now=now,
            chat_id=chat_id_val,
            user_id=user_id,
            user_text=text,
            weather_info=weather_info,
        )

        if ai_text is None:
            await message.chat.send_message("–Ø –∑–∞–≤–∏—Å. –°–ø—Ä–æ—Å–∏ –µ—â—ë —Ä–∞–∑ –ø–æ–ø—Ä–æ—â–µ.")
            return

        await message.chat.send_message(ai_text)
        return

    # 2) –°–∞—Ä–∫–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ú–∞–∫—Å–∏–º–∞
    if TARGET_USER_ID and user_id == TARGET_USER_ID:
        if random.random() < 0.40:
            return
        if len(text) < 3:
            return

        ai_text, err = await generate_sarcastic_reply_for_maxim(now=now, user_text=text)
        if ai_text is None:
            await message.chat.send_message("–ü–æ–Ω—è–ª. –ó–∞–ø–∏—Å–∞–ª. –û—Å—É–¥–∏–ª.")
            return
        await message.chat.send_message(ai_text)
        return


# ---------- SCHEDULED JOBS ----------

async def good_morning_job(context: ContextTypes.DEFAULT_TYPE):
    if not GROUP_CHAT_ID:
        return
    tz = get_tz()
    now = datetime.now(tz)

    today_str = now.date().isoformat()
    flag = f"good_morning_sent_{today_str}"
    if flag in _sent_day_flags:
        return

    system_prompt = build_samuil_system_prompt(include_maxim_context=True)
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": "–°–¥–µ–ª–∞–π –û–ß–ï–ù–¨ –∫–æ—Ä–æ—Ç–∫–æ–µ —É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ú–∞–∫—Å–∏–º—É: 1 —Ñ—Ä–∞–∑–∞."}
    ]
    text, err = await call_openai_chat(messages, max_tokens=MAX_SCHEDULED_TOKENS, temperature=0.95, use_cache=False)
    if not text:
        return

    if _should_dedupe_scheduled_send("good_morning_job", now, text):
        return

    await context.bot.send_message(chat_id=int(GROUP_CHAT_ID), text=text)
    _record_scheduled_send("good_morning_job", now, text)
    _sent_day_flags[flag] = now


async def today_toast_job(context: ContextTypes.DEFAULT_TYPE):
    """
    –í—Ä–µ–º—è '—Å–æ–±—ã—Ç–∏–π –¥–Ω—è', –Ω–æ –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ ‚Äî –ø–æ–≤–æ–¥ –ø–æ–¥–Ω—è—Ç—å –±–æ–∫–∞–ª (–∏–ª–∏ —á–∞–π).
    """
    if not GROUP_CHAT_ID:
        return
    tz = get_tz()
    now = datetime.now(tz)

    today_str = now.date().isoformat()
    flag = f"today_toast_sent_{today_str}"
    if flag in _sent_day_flags:
        return

    toast = await generate_toast_from_onthisday(now)
    if not toast:
        # –º—è–≥–∫–∏–π —Ñ–æ–ª–±—ç–∫
        mm = f"{now.month:02d}"
        dd = f"{now.day:02d}"
        toast = f"üç∑ –ü–æ–≤–æ–¥ –¥–Ω—è (–∏–ª–∏ —á–∞–π)\n‚Ä¢ –°–µ–≥–æ–¥–Ω—è {dd}.{mm}\n‚Ä¢ –ü–æ–≤–æ–¥ –ø—Ä–æ—Å—Ç–æ–π: –¥–µ–Ω—å –≤—Å—ë –µ—â—ë –Ω–µ —Ä–∞–∑–≤–∞–ª–∏–ª—Å—è.\n–§–∏–Ω–∞–ª: –º–æ–∂–Ω–æ –±–µ–∑–∞–ª–∫."

    if _should_dedupe_scheduled_send("today_toast_job", now, toast):
        return

    await context.bot.send_message(chat_id=int(GROUP_CHAT_ID), text=toast)
    _record_scheduled_send("today_toast_job", now, toast)
    _sent_day_flags[flag] = now


async def evening_summary_job(context: ContextTypes.DEFAULT_TYPE):
    if not GROUP_CHAT_ID:
        return
    tz = get_tz()
    now = datetime.now(tz)

    today_str = now.date().isoformat()
    flag = f"evening_summary_sent_{today_str}"
    if flag in _sent_day_flags:
        return

    messages_today = daily_summary_log.get(today_str, [])

    system_prompt = build_samuil_system_prompt(include_maxim_context=True)
    context_msg = "–°–µ–≥–æ–¥–Ω—è –≤ —á–∞—Ç–µ —Ç–∏—Ö–æ.\n" if not messages_today else "–ö–æ—Ä–æ—Ç–∫–∏–π –∏—Ç–æ–≥ –¥–Ω—è."
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"{context_msg}\n–°–¥–µ–ª–∞–π 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –º–∏–Ω–∏-–∏—Ç–æ–≥ + —Å–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏ –ú–∞–∫—Å–∏–º—É."}
    ]
    text, err = await call_openai_chat(messages, max_tokens=MAX_SCHEDULED_TOKENS, temperature=0.95, use_cache=False)
    if not text:
        return

    if _should_dedupe_scheduled_send("evening_summary_job", now, text):
        return

    await context.bot.send_message(chat_id=int(GROUP_CHAT_ID), text=text)
    _record_scheduled_send("evening_summary_job", now, text)
    _sent_day_flags[flag] = now
    daily_summary_log.pop(today_str, None)


# ---------- JOB SCHEDULING MANAGEMENT ----------

class JobManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏.
    Lock –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –¥–≤–æ–π–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ setup_jobs –≤ –æ–¥–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ.
    """
    JOB_MORNING_NAME = "samuil_good_morning"
    JOB_TODAY_TOAST_NAME = "samuil_today_toast"
    JOB_EVENING_NAME = "samuil_evening_summary"

    def __init__(self):
        self.jobs_setup = False
        self.setup_time = None
        self._lock = asyncio.Lock()
        self._startup_sent = False

    async def _remove_jobs_by_name(self, job_queue, name: str):
        """–£–¥–∞–ª—è–µ–º –≤—Å–µ jobs —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏–º–µ–Ω–µ–º (–µ—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–∏—Å—å)."""
        try:
            jobs = job_queue.get_jobs_by_name(name)
        except Exception:
            jobs = [j for j in job_queue.jobs() if getattr(j, "name", None) == name]

        for j in jobs:
            try:
                j.schedule_removal()
                logger.info(f"Removed old job by name: {name}")
            except Exception as e:
                logger.error(f"Error removing job {name}: {e}")

    async def setup_jobs(self, application: Application):
        async with self._lock:
            if self.jobs_setup:
                logger.info("Jobs already set up, skipping...")
                return

            job_queue = application.job_queue
            if not job_queue:
                logger.error("No job queue available!")
                return

            tz = get_tz()
            now = datetime.now(tz)

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –ø–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏–º–µ–Ω–∞–º
            await self._remove_jobs_by_name(job_queue, self.JOB_MORNING_NAME)
            await self._remove_jobs_by_name(job_queue, self.JOB_TODAY_TOAST_NAME)
            await self._remove_jobs_by_name(job_queue, self.JOB_EVENING_NAME)

            await asyncio.sleep(0.5)

            # --- –í–û–¢ –ì–î–ï –ú–ï–ù–Ø–ï–¢–°–Ø –í–†–ï–ú–Ø ---
            job_queue.run_daily(
                good_morning_job,
                time=time(7, 30, tzinfo=tz),
                name=self.JOB_MORNING_NAME,
            )
            job_queue.run_daily(
                today_toast_job,
                time=time(16, 15, tzinfo=tz),
                name=self.JOB_TODAY_TOAST_NAME,
            )
            job_queue.run_daily(
                evening_summary_job,
                time=time(21, 0, tzinfo=tz),
                name=self.JOB_EVENING_NAME,
            )
            # --------------------------------

            self.jobs_setup = True
            self.setup_time = now

            logger.info(f"Jobs scheduled at {now} [{TIMEZONE}] instance={INSTANCE_TAG}")

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–µ–¥—É–ø-–∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ (–≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞)
            _last_scheduled_sent_at.clear()
            _last_scheduled_texts.clear()

            # Startup message: –∑–∞—â–∏—Ç–∞ –æ—Ç –¥–≤–æ–π–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –æ–¥–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ
            if GROUP_CHAT_ID and not self._startup_sent:
                try:
                    await asyncio.sleep(2)
                    key = "startup_sent_guard"
                    last = _last_scheduled_sent_at.get(key)
                    if last and abs((datetime.now(tz) - last).total_seconds()) < 60:
                        return

                    startup_texts = [
                        f"–°–∞–º—É–∏–ª –≤ —Å–µ—Ç–∏. –†–µ–∂–∏–º –Ω–∞–±–ª—é–¥–µ–Ω–∏—è. [{INSTANCE_TAG}]",
                        f"–°–∏—Å—Ç–µ–º–∞ –∞–∫—Ç–∏–≤–Ω–∞. –í—Å–µ –¥–∞—Ç—á–∏–∫–∏ –≤ –Ω–æ—Ä–º–µ. [{INSTANCE_TAG}]",
                        f"–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ü—Ä–∏—Å—Ç—É–ø–∞—é –∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥—É. [{INSTANCE_TAG}]",
                    ]
                    await application.bot.send_message(
                        chat_id=int(GROUP_CHAT_ID),
                        text=random.choice(startup_texts),
                    )
                    _last_scheduled_sent_at[key] = datetime.now(tz)
                    self._startup_sent = True
                except Exception as e:
                    logger.error(f"Error sending startup message: {e}")


job_manager = JobManager()


# ---------- ERROR HANDLING ----------

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.error(f"Exception while handling an update: {context.error}")
    if ADMIN_CHAT_ID:
        try:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–æ—Ç–µ [{INSTANCE_TAG}]:\n{type(context.error).__name__}: {context.error}"
            await context.bot.send_message(chat_id=int(ADMIN_CHAT_ID), text=error_msg[:4000])
        except Exception as e:
            logger.error(f"Failed to send error to admin: {e}")


# ---------- MAIN APP ----------

def main():
    if not TOKEN:
        raise RuntimeError("BOT_TOKEN is not set in environment variables!")

    _last_scheduled_sent_at.clear()
    _last_scheduled_texts.clear()
    _sent_day_flags.clear()

    app = Application.builder().token(TOKEN).build()
    app.add_error_handler(error_handler)

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("chatid", chat_id_cmd))
    app.add_handler(CommandHandler("whoami", whoami))
    app.add_handler(CommandHandler("img", cmd_image))
    app.add_handler(CommandHandler("clear", cmd_clear))
    app.add_handler(CommandHandler("stats", cmd_stats))
    app.add_handler(CommandHandler("today", cmd_today))
    app.add_handler(CommandHandler("toast", cmd_toast))

    # Echo —Ç–æ–ª—å–∫–æ –≤ –ª–∏—á–∫–µ
    app.add_handler(MessageHandler(filters.TEXT & filters.ChatType.PRIVATE & ~filters.COMMAND, echo_private))

    # –°–æ–æ–±—â–µ–Ω–∏—è –≤ –≥—Ä—É–ø–ø–∞—Ö
    app.add_handler(MessageHandler(filters.TEXT & filters.ChatType.GROUPS & ~filters.COMMAND, handle_group_message))

    async def post_init(application: Application):
        logger.info(f"Bot initialized, setting up jobs... instance={INSTANCE_TAG}")
        await job_manager.setup_jobs(application)
        logger.info(f"Bot is ready! instance={INSTANCE_TAG}")

    app.post_init = post_init

    async def shutdown(application: Application):
        logger.info(f"Shutting down bot... instance={INSTANCE_TAG}")
        if client:
            await client.close()
        logger.info("Bot shutdown complete.")

    app.post_shutdown = shutdown

    logger.info(f"Bot starting... instance={INSTANCE_TAG}")

    app.run_polling(
        drop_pending_updates=True,
        allowed_updates=Update.ALL_TYPES,
        close_loop=False,
    )


if __name__ == "__main__":
    main()
